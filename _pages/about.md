---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a Senior Researcher at [Microsoft Research](https://www.microsoft.com/en-us/research/about-microsoft-research/).
I received my Bachelor's degree and Ph.D. from [Tsinghua University](https://www.tsinghua.edu.cn/en/index.htm) in 2016 and 2021, respectively.
My recent research focuses on multimodal modeling, embodied AI, and efficient LLMs. <!--Information Extraction and low-resource NLP.-->

ðŸ“¢ I'm looking for a self-motivated research intern who is passionate about GUI agents and embodied agents. If you are interested in this topic, feel free to email me your resume and a brief self-intro!

News
------
* [ 06/03/2025 ] Excited to release our [GUI-Actor](https://github.com/microsoft/GUI-Actor), a coordinate-free visual grounding method for GUI agents!
* [ 04/28/2025 ] You're welcome to join our [4th Workshop on Computer Vision in the Wild (CVinW) at @CVPR 2025](https://computer-vision-in-the-wild.github.io/cvpr-2025)!
* [ 02/26/2025 ] [Magma](https://microsoft.github.io/Magma/) is accepted by CVPR 2025!
* [ 02/18/2025 ] We release [Magma](https://microsoft.github.io/Magma/), a foundation model for multimodal AI agents!
* [ 01/22/2025 ] [SeCom](https://www.microsoft.com/en-us/research/project/secom/) and [SCBench](https://arxiv.org/abs/2412.10319) are accepted at ICLR 2025!
* [ 09/25/2024 ] [MInference](https://arxiv.org/abs/2406.02536) is accepted at NeurIPS 2024 as a spotlight!
<!--* [ 09/14/2024 ] I'm serving as an Area Chair for COLING 25!-->
<!--* [ 06/03/2024 ] [MInference](https://arxiv.org/abs/2407.02490) and [LLM Position Bias paper](https://arxiv.org/abs/2406.02536) are accepted to ES-FoMo II @ ICML24 and LCFM @ ICML24, respectively.-->
* [ 05/21/2024 ] [LLMLingua Series](https://llmlingua.com/llmlingua.html) has been integrated as a custom tool in [Prompt Flow](https://microsoft.github.io/promptflow/integrations/tools/llmlingua-prompt-compression-tool.html#introduction), [AutoGen](https://microsoft.github.io/autogen/0.2/docs/topics/handling_long_contexts/compressing_text_w_llmligua), [LangChain](https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/retrievers/llmlingua.ipynb) and [LlamaIndex](https://github.com/run-llama/llama_index/blob/main/llama-index-legacy/llama_index/legacy/postprocessor/longllmlingua.py).
<!--* [05/16/2024] [LongLLMLingua](https://llmlingua.com/longllmlingua.html) and [LLMLingua-2](https://llmlingua.com/llmlingua2.html) are accepted to ACL-2024 in main track and findings.-->
<!--* [03/19/2024] We release [LLMLingua-2](https://llmlingua.com/llmlingua2.html), an efficient option for task-agnostic prompt compression with good performance and generalizability across different scenarios, boasting a 3x-6x speed improvement over LLMLingua.-->
<!--* [02/28/2023] [LLMLingua Series](https://llmlingua.com/) has been integrated into [LangChain](https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/retrievers/llmlingua.ipynb) and [LlamaIndex](https://github.com/run-llama/llama_index/blob/main/llama-index-legacy/llama_index/legacy/postprocessor/longllmlingua.py).-->
<!--* [02/28/2024] [LLMLingua Series](https://llmlingua.com/) has been added as a document compressor in [LangChain](https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/retrievers/llmlingua.ipynb).-->
<!--* [10/26/2023] [LLMLingua Series](https://llmlingua.com/) has been integrated into [LlamaIndex](https://github.com/run-llama/llama_index/blob/main/llama-index-legacy/llama_index/legacy/postprocessor/longllmlingua.py).-->
<!--* [10/10/2023] We release [LongLLMLingua](https://llmlingua.com/longllmlingua.html), aiming to accelerate and enhance LLM inference in long-context scenarios via question-aware prompt compression and content reorganization.-->
<!--* [10/09/2023] We release [LLMLingua](https://llmlingua.com/llmlingua.html), a coarse-to-fine prompt compression method based on perplexity from a small language model such as LLaMA-7B.-->

Recommended Repos
------
* [GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents](https://github.com/microsoft/GUI-Actor) [![Stars](https://img.shields.io/github/stars/microsoft/GUI-Actor?color=yellow&style=social)](https://github.com/microsoft/GUI-Actor)
* [Magma: A Foundation Model for Multimodal AI Agents](https://microsoft.github.io/Magma/) [![Stars](https://img.shields.io/github/stars/microsoft/Magma?color=yellow&style=social)](https://github.com/microsoft/Magma)
* [MInference: Million-Tokens Prompt Inference for Long-context LLMs](https://arxiv.org/abs/2407.02490) [![Stars](https://img.shields.io/github/stars/microsoft/MInference?color=yellow&style=social)](https://github.com/microsoft/MInference)
* [LLMLingua Series for Prompt Compression](https://github.com/microsoft/LLMLingua) [![Stars](https://img.shields.io/github/stars/microsoft/LLMLingua?color=yellow&style=social)](https://github.com/microsoft/LLMLingua)
* [Versatile Entity Recognition & disambiguation Toolkit](https://github.com/microsoft/vert-papers) [![Stars](https://img.shields.io/github/stars/microsoft/vert-papers?color=yellow&style=social)](https://github.com/microsoft/vert-papers)

Selected Publications
------
* **Qianhui Wu*** , Kanzhi Cheng* , Rui Yang*, Chaoyun Zhang, Jianwei Yang, Huiqiang Jiang, Jian Mu, Baolin Peng, Bo Qiao, Reuben Tan, Si Qin, Lars Liden, Qingwei Lin, Huan Zhang, Tong Zhang, Jianbing Zhang, Dongmei Zhang, Jianfeng Gao, [GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents](https://microsoft.github.io/GUI-Actor/), preprint.
* Jianwei Yang* , Reuben Tan* , **Qianhui Wu***, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai, Seonghyeon Ye, Joel Jang, Yuquan Deng, Jianfeng Gao, [Magma: A Foundation Model for Multimodal AI Agents](https://microsoft.github.io/Magma/), CVPR-2025.
* Zhuoshi Pan, **Qianhui Wu**, Huiqiang Jiang, Xufang Luo, Hao Cheng, Dongsheng Li, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Jianfeng Gao, [Secom: On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2403.12968v1), ICLR-2025, AFM@NeurIPS-2024.
* Yucheng Li, Huiqiang Jiang, **Qianhui Wu**, Xufang Luo, Surin Ahn, Chengruidong Zhang, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu, [SharedContextBench: How Lossy are Long-context Methods in KV Cache Reuse](https://arxiv.org/abs/2412.10319), ICLR-2025.
* Huiqiang Jiang* , Yucheng Li* , Chengruidong Zhang*, **Qianhui Wu**, Xufang Luo, Surin Ahn, Zhenhua Han, Amir H. Abdi, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu, [MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention](https://arxiv.org/abs/2407.02490), NeurIPS-2024 spotlight.
* Zhoshi Pan, **Qianhui Wu**, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin, Victor RÃ¼hle, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Dongmei Zhang, [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](https://arxiv.org/html/2403.12968v1), ACL-2024 Findings.
* Huiqiang Jiang, **Qianhui Wu**, Xufang Luo, Dongshegn Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu, [LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression](https://arxiv.org/abs/2310.06839), ACL-2024, ME-FoMo@ICLR-2024.
<!--* Tingting Ma, **Qianhui Wu**, Huiqiang Jiang, Jieru Lin, BÃ¶rje Karlsson, Tiejun Zhao, Chin-Yew Lin, [Decomposed Meta-Learning for Few-Shot Sequence Labeling](https://ieeexplore.ieee.org/document/10458261/), TASLP-2024.-->
* Huiqiang Jiang, **Qianhui Wu**, Chin-Yew Lin, Yuqing Yang, Lili Qiu, [LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models](https://aclanthology.org/2023.emnlp-main.825/), EMNLP-2023.
* **Qianhui Wu**, Huiqiang Jiang, Haonan Yin, BÃ¶rje Karlsson, Chin-Yew Lin, [Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text](https://aclanthology.org/2023.acl-long.403/), ACL-2023.
<!--* Tingting Ma, **Qianhui Wu**, Huiqiang Jiang, BÃ¶rje Karlsson, Tiejun Zhao, Chin-Yew Lin, [CoLaDa: A Collaborative Label Denoising Framework for Cross-lingual Named Entity Recognition](https://aclanthology.org/2023.acl-long.330/), ACL-2023.-->
<!--* Tingting Ma* , Huiqiang Jiang* , **Qianhui Wu***, Tiejun Zhao, Chin-Yew Lin, [Decomposed Meta-Learning for Few-Shot Named Entity Recognition](https://aclanthology.org/2022.findings-acl.124/), ACL-2022 Findings.-->
<!--* Tingting Ma, **Qianhui Wu**, Zhiwei Yu, Tiejun Zhao, Chin-Yew Lin, [On the Effectiveness of Sentence Encoding for Intent Detection Meta-Learning](https://aclanthology.org/2022.naacl-main.279/), NAACL-2022.-->
<!--* Yu Mo* , **Qianhui Wu***, Xiu Li, Biqing Huang, [Remaining Useful Life Estimation via Transformer Encoder Enhanced by a Gated Convolutional Unit](https://link.springer.com/article/10.1007/s10845-021-01750-x), JIM-2021.-->
<!--* **Qianhui Wu**, Zijia Lin, BÃ¶rje Karlsson, Biqing Huang, Jian-Guang Lou, [Unitrans: Unifying Model Transfer and Data Transfer for Cross-Lingual Named Entity Recognition with Unlabeled Data](https://www.ijcai.org/Proceedings/2020/0543.pdf), IJCAI-2020.-->
<!--* **Qianhui Wu**, Zijia Lin, BÃ¶rje Karlsson, Jian-Guang Lou, Biqing Huang, [Single-/Multi-Source Cross-Lingual NER via Teacher-Student Learning on Unlabeled Data in Target Language](https://aclanthology.org/2020.acl-main.581/), ACL-2020.-->
<!--* **Qianhui Wu**, Zijia Lin, Guoxin Wang, Hui Chen, BÃ¶rje Karlsson, Biqing Huang, Chin-Yew Lin, [Enhanced Meta-Learning for Cross-Lingual Named Entity Recognition with Minimal Resources](https://aaai.org/papers/09274-enhanced-meta-learning-for-cross-lingual-named-entity-recognition-with-minimal-resources/), AAAI-2020 spotlight.-->
<!--* **Qianhui Wu*** , Guoxin Wang*, Yuyin Zhu, Haoyan Liu, BÃ¶rje Karlsson, [DeepMRT at the NTCIR-14 FinNum task: a hybrid neural model for numeral type classification in financial tweets](https://research.nii.ac.jp/ntcir/workshop/OnlineProceedings14/pdf/ntcir/07-NTCIR14-FINNUM-WuQ.pdf), NTCIR-2019.-->
<!--* **Qianhui Wu**, Keqin Ding, Biqing Huang, [Approach for Fault Prognosis Using Recurrent Neural Network](https://link.springer.com/article/10.1007/s10845-018-1428-5), JIM-2018.-->

Honors & Awards
------
* [Microsoft 2024 Global Hackathon Executive Challenge Winner](https://www.credly.com/earner/earned/badge/c5462195-58cb-4ea3-bfa6-421f28d14c70) (2024)
* [Microsoft Machine Learning, AI & Data Science Conference (MLADS) Distinguished Contribution](https://www.credly.com/badges/de094913-37b0-441d-ac1d-955d3c01ef1d) Award Winner (2024)
* [Microsoft 2023 Global Hackathon Award Winner](https://www.credly.com/badges/2f60ed04-4548-4d7c-a80f-c765ad6cee0f) (2023)
<!--* Outstanding Intern of "Stars of Tomorrow" Program, Microsoft Research Asia (2020)-->
* Intel Scholarship (2020)
<!--* Second Place Winner of NTCIR-2019 FinNum Task (2019)-->
<!--* Second-Class Scholarship, Tsinghua University (2018)-->
* Outstanding (12-9) Counselor Prize, Tsinghua University (2018)
* Outstanding Bachelor Thesis, Tsinghua University (2016)
<!--* Second Prize of Challenge Cup, Tsinghua University (2015)-->
* National Encouragement Scholarship (2014)
* Scholarship of Art Excellence, Tsinghua University (2014)
* Scholarship of Academic Excellence, Tsinghua University (2013)

Other Information
------
**Invited Talks**
* [ 09/05/2025 ] Towards AI Agents That Can See And Act @ Shanghai Artificial Intelligence Laboratory
* [ 06/25/2025 ] Act Where You See: Coordinate-Free Visual Grounding for GUI Agents @ Simular Seminar

**Academic Service**
* Area Chair: COLING-25.
* Conference Reviewer: ICLR, NeurIPS, ACL, EMNLP, NAACL, AAAI, NLPCC.
* Journal Reviewer: CSUR, Pattern Recognition, TASLP, IPM, JIM, ESIN, SIVP, Scientific Reports.

**Other Activities**
* Counselor at Center for Student Learning and Development, Tsinghua University (Sep. 2016 - Aug. 2018)
* Member of Chinese National Orchestra, Tsinghua University (Aug. 2012 - Jun. 2021)

------
<div style="width: 400px; margin: auto;">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=a&t=tt&d=sHUFovnSB1DX6vMbdeo1Jz4d6fXjO90cNXCmDhzb3e4&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
</div>
