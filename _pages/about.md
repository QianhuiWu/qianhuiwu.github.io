---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a Senior Researcher at [Microsoft Research](https://www.microsoft.com/en-us/research/about-microsoft-research/).
I received my Bachelor's degree and Ph.D. from [Tsinghua University](https://www.tsinghua.edu.cn/en/index.htm) in 2016 and 2021, respectively.
My recent research focuses on computer use agents, tool calling, and agentic AI. <!--Information Extraction and low-resource NLP, Efficient LLMs.-->

üì¢ I'm looking for a self-motivated research intern who is passionate about AI agents (GUI/embodied agents, tool calling, and context management). If you are interested in these topics, feel free to email me your resume and a brief self-intro!

News üåü
------
<span class="news-date">Jan. 2026</span> Welcome to join our [5th Workshop on Computer Vision in the Wild (CVinW) at @CVPR 2026](https://computer-vision-in-the-wild.github.io/cvpr-2026)!<br>
<span class="news-date">Jan. 2026</span> We release [SynthAgent](https://github.com/aiming-lab/SynthAgent), a task and trajectory synthetic framework for web agents!<br>
<span class="news-date">Jan. 2026</span> [Dyna-Mind](https://arxiv.org/pdf/2510.09577) is accepted by ICLR 2026!<br>
<span class="news-date">Dec. 2025</span> We release [Argos](https://arxiv.org/pdf/2511.04307), a principled reward agent to train LMRMs for agentic tasks.<br>
<span class="news-date">Nov. 2025</span> We release [GUI-360](https://arxiv.org/pdf/2511.04307), a comprehensive dataset and benchmark for CUA!<br>
<span class="news-date">Jun. 2025</span> Excited to release [GUI-Actor](https://github.com/microsoft/GUI-Actor), a coordinate-free visual grounding method for GUI agents!<br>

<details markdown="1">
<summary style="cursor: pointer; color: #52adc8; margin-top: 5px;">Show more news</summary>

<span class="news-date">Apr. 2025</span> You're welcome to join our [4th Workshop on Computer Vision in the Wild (CVinW) at @CVPR 2025](https://computer-vision-in-the-wild.github.io/cvpr-2025)!<br>
<span class="news-date">Apr. 2025</span> We release [MMInference](http://aka.ms/mminference), accelerating pre-filling for long-context VLMs!<br>
<span class="news-date">Feb. 2025</span> We release [Magma](https://microsoft.github.io/Magma/), a foundation model for multimodal AI agents!<br>
<span class="news-date">Jan. 2025</span> [SeCom](https://www.microsoft.com/en-us/research/project/secom/) and [SCBench](https://arxiv.org/abs/2412.10319) are accepted at ICLR 2025!<br>
<span class="news-date">Sep. 2024</span> [MInference](https://arxiv.org/abs/2406.02536) is accepted at NeurIPS 2024 as a spotlight!<br>
<span class="news-date">Sep. 2024</span> I'm serving as an Area Chair for COLING 25!<br>
<span class="news-date">Jun. 2024</span> [MInference](https://arxiv.org/abs/2407.02490) and [LLM Position Bias paper](https://arxiv.org/abs/2406.02536) are accepted to ES-FoMo II @ ICML24 and LCFM @ ICML24, respectively.<br>
<span class="news-date">May. 2024</span> [LLMLingua Series](https://llmlingua.com/llmlingua.html) has been integrated as a custom tool in [Prompt Flow](https://microsoft.github.io/promptflow/integrations/tools/llmlingua-prompt-compression-tool.html#introduction), [AutoGen](https://microsoft.github.io/autogen/0.2/docs/topics/handling_long_contexts/compressing_text_w_llmligua), [LangChain](https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/retrievers/llmlingua.ipynb) and [LlamaIndex](https://github.com/run-llama/llama_index/blob/main/llama-index-legacy/llama_index/legacy/postprocessor/longllmlingua.py).<br>
<span class="news-date">May. 2024</span> [LongLLMLingua](https://llmlingua.com/longllmlingua.html) and [LLMLingua-2](https://llmlingua.com/llmlingua2.html) are accepted to ACL-2024 in main track and findings!<br>
<span class="news-date">Mar. 2024</span> We release [LLMLingua-2](https://llmlingua.com/llmlingua2.html), an efficient option for task-agnostic prompt compression with good performance and generalizability across different scenarios, boasting a 3x-6x speed improvement over LLMLingua!<br>
<!--<span class="news-date">02/28/2024</span> [LLMLingua Series](https://llmlingua.com/) has been added as a document compressor in [LangChain](https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/retrievers/llmlingua.ipynb).-->
<!--<span class="news-date">10/26/2023</span> [LLMLingua Series](https://llmlingua.com/) has been integrated into [LlamaIndex](https://github.com/run-llama/llama_index/blob/main/llama-index-legacy/llama_index/legacy/postprocessor/longllmlingua.py).-->
<span class="news-date">Oct. 2023</span> We release [LongLLMLingua](https://llmlingua.com/longllmlingua.html), aiming to accelerate and enhance LLM inference in long-context scenarios via question-aware prompt compression and content reorganization!<br>
<span class="news-date">Oct. 2023</span> We release [LLMLingua](https://llmlingua.com/llmlingua.html), a coarse-to-fine prompt compression method based on perplexity from a small language model such as LLaMA-7B!<br>

</details>

Recommended Repos üß∞
------
* [GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents](https://github.com/microsoft/GUI-Actor) [![Stars](https://img.shields.io/github/stars/microsoft/GUI-Actor?color=yellow&style=social)](https://github.com/microsoft/GUI-Actor)
* [Magma: A Foundation Model for Multimodal AI Agents](https://microsoft.github.io/Magma/) [![Stars](https://img.shields.io/github/stars/microsoft/Magma?color=yellow&style=social)](https://github.com/microsoft/Magma)
* [MInference: Million-Tokens Prompt Inference for Long-context LLMs](https://github.com/microsoft/MInference) [![Stars](https://img.shields.io/github/stars/microsoft/MInference?color=yellow&style=social)](https://github.com/microsoft/MInference)
* [LLMLingua Series for Prompt Compression](https://github.com/microsoft/LLMLingua) [![Stars](https://img.shields.io/github/stars/microsoft/LLMLingua?color=yellow&style=social)](https://github.com/microsoft/LLMLingua)
* [Versatile Entity Recognition & disambiguation Toolkit](https://github.com/microsoft/vert-papers) [![Stars](https://img.shields.io/github/stars/microsoft/vert-papers?color=yellow&style=social)](https://github.com/microsoft/vert-papers)

Selected Publications üìö
------
<details markdown="1" open>
<summary style="cursor: pointer; margin-top: 5px;"><strong>Agentic AI</strong></summary>

* <span class="news-date">Preprint 2026</span> [GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL](https://arxiv.org/abs/2602.22190)
   <br>Rui Yang, **Qianhui Wu**, Zhaoyang Wang, Hanyang Chen, Ke Yang, Hao Cheng, Huaxiu Yao, Baoling Peng, Huan Zhang, Jianfeng Gao, Tong Zhang
* <span class="news-date">Preprint 2025</span> [Multimodal Reinforcement Learning with Agentic Verifier for AI Agents](https://arxiv.org/abs/2512.03438)
   <br>Reuben Tan, Baolin Peng, Zhengyuan Yang, Hao Cheng, Oier Mees, Theodore Zhao, Andrea Tupini, Isar Meijier, **Qianhui Wu**, Yuncong Yang, Lars Liden, Yu Gu, Sheng Zhang, Xiaodong Liu, Lijuan Wang, Marc Pollefeys, Yong Jae Lee, Jianfeng Gao
* <span class="news-date">Preprint 2025</span> [Adapting Web Agents with Synthetic Supervision](https://arxiv.org/pdf/2511.06101)
   <br>Zhaoyang Wang, Yiming Liang, Xuchao Zhang, **Qianhui Wu**, Siwei Han, Anson Bastos, Rujia Wang, Chetan Bansal, Baolin Peng, Jianfeng Gao, Saravan Rajmohan, Huaxiu Yao
* <span class="news-date">Preprint 2025</span> [GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents](https://arxiv.org/html/2403.12968v1)
   <br>Jian Mu, Chaoyun Zhang, Chiming Ni, Lu Wang, Bo Qiao, Kartik Mathur, **Qianhui Wu**, Yuhang Xie, Xiaojun Ma, Mengyu Zhou, Si Qin, Liqun Li, Yu Kang, Minghua Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang
* <span class="news-date">ICLR-2026</span> [Dyna-Mind: Learning to Simulate from Experience for Better AI Agents](https://arxiv.org/pdf/2510.09577)
   <br>Xiao Yu, Baolin Peng, Michel Galley, Hao Cheng, **Qianhui Wu**, Janardhan Kulkarni, Suman Nath, Zhou Yu, Jianfeng Gao
* <span class="news-date">NeurIPS-2025</span> [GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents](https://microsoft.github.io/GUI-Actor/)
   <br>**Qianhui Wu**\*, Kanzhi Cheng\*, Rui Yang\*, Chaoyun Zhang, Jianwei Yang, Huiqiang Jiang, Jian Mu, Baolin Peng, Bo Qiao, Reuben Tan, Si Qin, Lars Liden, Qingwei Lin, Huan Zhang, Tong Zhang, Jianbing Zhang, Dongmei Zhang, Jianfeng Gao.
* <span class="news-date">CVPR-2025</span> [Magma: A Foundation Model for Multimodal AI Agents](https://microsoft.github.io/Magma/)
   <br>Jianwei Yang\*, Reuben Tan\*, **Qianhui Wu**\*, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai, Seonghyeon Ye, Joel Jang, Yuquan Deng, Jianfeng Gao.
* <span class="news-date">ICLR-2025</span> [SeCom: On Memory Construction and Retrieval for Personalized Conversational Agents](https://arxiv.org/html/2403.12968v1)
   <br>Zhuoshi Pan, **Qianhui Wu**, Huiqiang Jiang, Xufang Luo, Hao Cheng, Dongsheng Li, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Jianfeng Gao.

</details>

<details markdown="1">
<summary style="cursor: pointer; margin-top: 5px;"><strong>Efficient LLM Inference</strong></summary>

* <span class="news-date">ICML-2025</span> [MMInference: Accelerating Pre-filling for Long-Context Visual Language Models via Modality-Aware Permutation Sparse Attention](https://hqjiang.com/mminference.html)
   <br>Yucheng Li, Huiqiang Jiang, Chengruidong Zhang, **Qianhui Wu**, Xufang Luo, Surin Ahn, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu.
* <span class="news-date">ICLR-2025</span> [SharedContextBench: How Lossy are Long-context Methods in KV Cache Reuse](https://arxiv.org/abs/2412.10319)
   <br>Yucheng Li, Huiqiang Jiang, **Qianhui Wu**, Xufang Luo, Surin Ahn, Chengruidong Zhang, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu.
* <span class="news-date">NeurIPS-2024</span> [MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention](https://arxiv.org/abs/2407.02490)
   <br>Huiqiang Jiang\*, Yucheng Li\*, Chengruidong Zhang\*, **Qianhui Wu**, Xufang Luo, Surin Ahn, Zhenhua Han, Amir H. Abdi, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu.
* <span class="news-date">ACL-2024 Findings</span> [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](https://arxiv.org/html/2403.12968v1)
   <br>Zhuoshi Pan, **Qianhui Wu**, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin, Victor R√ºhle, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Dongmei Zhang.
* <span class="news-date">ACL-2024</span> [LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression](https://arxiv.org/abs/2310.06839)
   <br>Huiqiang Jiang, **Qianhui Wu**, Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu.
* <span class="news-date">EMNLP-2023</span> [LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models](https://aclanthology.org/2023.emnlp-main.825/)
   <br>Huiqiang Jiang, **Qianhui Wu**, Chin-Yew Lin, Yuqing Yang, Lili Qiu.
* <span class="news-date">ACL-2023</span> [Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text](https://aclanthology.org/2023.acl-long.403/)
   <br>**Qianhui Wu**, Huiqiang Jiang, Haonan Yin, B√∂rje Karlsson, Chin-Yew Lin.

</details>

<details markdown="1">
<summary style="cursor: pointer; margin-top: 5px;"><strong>Information Extraction & Low-Resource NLP</strong></summary>

* <span class="news-date">ACL-2023</span> [CoLaDa: A Collaborative Label Denoising Framework for Cross-lingual Named Entity Recognition](https://aclanthology.org/2023.acl-long.330/)
    <br>Tingting Ma, **Qianhui Wu**, Huiqiang Jiang, B√∂rje Karlsson, Tiejun Zhao, Chin-Yew Lin.
* <span class="news-date">ACL-2022 Findings</span> [Decomposed Meta-Learning for Few-Shot Named Entity Recognition](https://aclanthology.org/2022.findings-acl.124/)
    <br>Tingting Ma\*, Huiqiang Jiang\*, **Qianhui Wu**\*, Tiejun Zhao, Chin-Yew Lin.
* <span class="news-date">NAACL-2022</span> [On the Effectiveness of Sentence Encoding for Intent Detection Meta-Learning](https://aclanthology.org/2022.naacl-main.279/)
    <br>Tingting Ma, **Qianhui Wu**, Zhiwei Yu, Tiejun Zhao, Chin-Yew Lin.
* <span class="news-date">IJCAI-2020</span> [UniTrans: Unifying Model Transfer and Data Transfer for Cross-Lingual Named Entity Recognition with Unlabeled Data](https://www.ijcai.org/Proceedings/2020/0543.pdf)
    <br>**Qianhui Wu**, Zijia Lin, B√∂rje Karlsson, Biqing Huang, Jian-Guang Lou.
* <span class="news-date">ACL-2020</span> [Single-/Multi-Source Cross-Lingual NER via Teacher-Student Learning on Unlabeled Data in Target Language](https://aclanthology.org/2020.acl-main.581/)
    <br>**Qianhui Wu**, Zijia Lin, B√∂rje Karlsson, Jian-Guang Lou, Biqing Huang.
* <span class="news-date">AAAI-2020</span> [Enhanced Meta-Learning for Cross-Lingual Named Entity Recognition with Minimal Resources](https://aaai.org/papers/09274-enhanced-meta-learning-for-cross-lingual-named-entity-recognition-with-minimal-resources/)
    <br>**Qianhui Wu**, Zijia Lin, Guoxin Wang, Hui Chen, B√∂rje Karlsson, Biqing Huang, Chin-Yew Lin.
* <span class="news-date">NTCIR-2019</span> [DeepMRT at the NTCIR-14 FinNum Task: A Hybrid Neural Model for Numeral Type Classification in Financial Tweets](https://research.nii.ac.jp/ntcir/workshop/OnlineProceedings14/pdf/ntcir/07-NTCIR14-FINNUM-WuQ.pdf)
    <br>**Qianhui Wu**\*, Guoxin Wang\*, Yuyin Zhu, Haoyan Liu, B√∂rje Karlsson.

</details>

Honors & Awards üèÜ
------
<span class="news-date">2024</span> [Microsoft 2024 Global Hackathon Executive Challenge Winner](https://www.credly.com/earner/earned/badge/c5462195-58cb-4ea3-bfa6-421f28d14c70)<br>
<span class="news-date">2024</span> [Microsoft Machine Learning, AI & Data Science Conference (MLADS) Distinguished Contribution](https://www.credly.com/badges/de094913-37b0-441d-ac1d-955d3c01ef1d)<br>
<span class="news-date">2023</span> [Microsoft 2023 Global Hackathon Award Winner](https://www.credly.com/badges/2f60ed04-4548-4d7c-a80f-c765ad6cee0f)<br>
<span class="news-date">2020</span> Outstanding Intern of "Stars of Tomorrow" Program, Microsoft Research Asia<br>
<span class="news-date">2020</span> Intel Scholarship<br>
<!--span class="news-date">2019</span> Second Place Winner of NTCIR-2019 FinNum Task<br-->
<!--span class="news-date">2018</span> Second-Class Scholarship, Tsinghua University<br-->
<span class="news-date">2018</span> Outstanding (12-9) Counselor Prize, Tsinghua University<br>
<span class="news-date">2016</span> Outstanding Bachelor Thesis, Tsinghua University<br>
<!--span class="news-date">2015</span> Second Prize of Challenge Cup, Tsinghua University<br-->
<span class="news-date">2014</span> National Encouragement Scholarship<br>
<span class="news-date">2014</span> Scholarship of Art Excellence, Tsinghua University<br>
<span class="news-date">2013</span> Scholarship of Academic Excellence, Tsinghua University

Other Information üìù
------
‚ñ∂ **Invited Talks**

<span class="news-date">Sep. 2025</span> Towards AI Agents That Can See And Act @ Shanghai Artificial Intelligence Laboratory<br>
<span class="news-date">Jun. 2025</span> Act Where You See: Coordinate-Free Visual Grounding for GUI Agents @ Simular Seminar

‚ñ∂ **Academic Service**

* Area Chair: COLING-25.
* Conference Reviewer: ICLR, NeurIPS, CVPR, ACL, EMNLP, NAACL, AAAI, NLPCC.
* Journal Reviewer: CSUR, TOIS, Pattern Recognition, TASLP, IPM, JIM, ESIN, SIVP.
<!--, Scientific Reports.-->

‚ñ∂ **Other Activities**

<span class="news-date">Sep. 2016 - Aug. 2018</span> Counselor at Center for Student Learning and Development, Tsinghua University<br>
<span class="news-date">Aug. 2012 - Jun. 2021</span> Member of Chinese National Orchestra, Tsinghua University

------
<div style="width: 400px; margin: auto;">
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=a&t=tt&d=sHUFovnSB1DX6vMbdeo1Jz4d6fXjO90cNXCmDhzb3e4&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
</div>
