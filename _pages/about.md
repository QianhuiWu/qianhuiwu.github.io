---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a Senior Researcher at [Microsoft](https://www.microsoft.com).
I received my Bachelor's degree and Ph.D. from [Tsinghua University](https://www.tsinghua.edu.cn/en/index.htm) in 2016 and 2021, respectively.
My recent research focuses on efficient LLMs and I'm also very interested in multimodal learning and embodied AI.
<!--Information Extraction and low-resource NLP.-->

News
------
* [06/03/2024] Our rencent work [MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention](https://arxiv.org/abs/2407.02490) and [Mitigate Position Bias in Large Language Models via Scaling a Single Dimension](https://arxiv.org/abs/2406.02536) are accepted to ES-FoMo II @ ICML24 and LCFM @ ICML24, respectively.
* [05/21/2024] [LLMLingua](https://llmlingua.com/llmlingua.html) has been integrated as a custom tool in [Prompt Flow](https://microsoft.github.io/promptflow/integrations/tools/llmlingua-prompt-compression-tool.html#introduction).
* [05/16/2024] [LongLLMLingua](https://llmlingua.com/longllmlingua.html) and [LLMLingua-2](https://llmlingua.com/llmlingua2.html) are accepted to ACL-2024 in main track and findings.
* [03/19/2024] We release [LLMLingua-2](https://llmlingua.com/llmlingua2.html), an efficient option for task-agnostic prompt compression with good performance and generalizability across different scenario, boasting a 3x-6x speed improvement over LLMLingua.
* [02/28/2023] [LLMLingua Series](https://llmlingua.com/) has been integrated into [LangChain](https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/retrievers/llmlingua.ipynb) and [LlamaIndex](https://github.com/run-llama/llama_index/blob/main/llama-index-legacy/llama_index/legacy/postprocessor/longllmlingua.py).
<!--* [02/28/2024] [LLMLingua Series](https://llmlingua.com/) has been added as a document compressor in [LangChain](https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/retrievers/llmlingua.ipynb).-->
<!--* [10/26/2023] [LLMLingua Series](https://llmlingua.com/) has been integrated into [LlamaIndex](https://github.com/run-llama/llama_index/blob/main/llama-index-legacy/llama_index/legacy/postprocessor/longllmlingua.py).-->
<!--* [10/10/2023] We release [LongLLMLingua](https://llmlingua.com/longllmlingua.html), aiming to accelerate and enhance LLM inference in long-context scenarios via question-aware prompt compression and content reorganization.-->
<!--* [10/09/2023] We release [LLMLingua](https://llmlingua.com/llmlingua.html), a coarse-to-fine prompt compression method based on perplexity from a small language model such as LLaMA-7B.-->

Recommended Repos
------
* [LLMLingua Series for Prompt Compression](https://github.com/microsoft/LLMLingua)[![Stars](https://img.shields.io/github/stars/microsoft/LLMLingua?color=yellow&style=social)](https://github.com/microsoft/LLMLingua)
* [Versatile Entity Recognition & disambiguation Toolkit](https://github.com/microsoft/vert-papers) [![Stars](https://img.shields.io/github/stars/microsoft/vert-papers?color=yellow&style=social)](https://github.com/microsoft/vert-papers)

Selected Publications
------
* Zhoshi Pan, **Qianhui Wu**, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin, Victor Rühle, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Dongmei Zhang, [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](https://arxiv.org/html/2403.12968v1), ACL-2024 Findings.
* Huiqiang Jiang, **Qianhui Wu**, Xufang Luo, Dongshegn Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu, [LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression](https://arxiv.org/abs/2310.06839), ACL-2024, ME-FoMo@ICLR-2024.
* Tingting Ma, **Qianhui Wu**, Huiqiang Jiang, Jieru Lin, Börje Karlsson, Tiejun Zhao, Chin-Yew Lin, [Decomposed Meta-Learning for Few-Shot Sequence Labeling](https://ieeexplore.ieee.org/document/10458261/), TASLP-2024.
* Huiqiang Jiang, **Qianhui Wu**, Chin-Yew Lin, Yuqing Yang, Lili Qiu, [LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models](https://aclanthology.org/2023.emnlp-main.825/), EMNLP-2023.
* **Qianhui Wu**, Huiqiang Jiang, Haonan Yin, Börje Karlsson, Chin-Yew Lin, [Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text](https://aclanthology.org/2023.acl-long.403/), ACL-2023.
* Tingting Ma, **Qianhui Wu**, Huiqiang Jiang, Börje Karlsson, Tiejun Zhao, Chin-Yew Lin, [CoLaDa: A Collaborative Label Denoising Framework for Cross-lingual Named Entity Recognition](https://aclanthology.org/2023.acl-long.330/), ACL-2023.
* Tingting Ma* , Huiqiang Jiang* , **Qianhui Wu***, Tiejun Zhao, Chin-Yew Lin, [Decomposed Meta-Learning for Few-Shot Named Entity Recognition](https://aclanthology.org/2022.findings-acl.124/), ACL-2022 Findings.
* Tingting Ma, **Qianhui Wu**, Zhiwei Yu, Tiejun Zhao, Chin-Yew Lin, [On the Effectiveness of Sentence Encoding for Intent Detection Meta-Learning](https://aclanthology.org/2022.naacl-main.279/), NAACL-2022.
* Yu Mo* , **Qianhui Wu***, Xiu Li, Biqing Huang, [Remaining Useful Life Estimation via Transformer Encoder Enhanced by a Gated Convolutional Unit](https://link.springer.com/article/10.1007/s10845-021-01750-x), JIM-2021.
* **Qianhui Wu**, Zijia Lin, Börje Karlsson, Biqing Huang, Jian-Guang Lou, [Unitrans: Unifying Model Transfer and Data Transfer for Cross-Lingual Named Entity Recognition with Unlabeled Data](https://www.ijcai.org/Proceedings/2020/0543.pdf), IJCAI-2020.
* **Qianhui Wu**, Zijia Lin, Börje Karlsson, Jian-Guang Lou, Biqing Huang, [Single-/Multi-Source Cross-Lingual NER via Teacher-Student Learning on Unlabeled Data in Target Language](https://aclanthology.org/2020.acl-main.581/), ACL-2020.
* **Qianhui Wu**, Zijia Lin, Guoxin Wang, Hui Chen, Börje Karlsson, Biqing Huang, Chin-Yew Lin, [Enhanced Meta-Learning for Cross-Lingual Named Entity Recognition with Minimal Resources](https://aaai.org/papers/09274-enhanced-meta-learning-for-cross-lingual-named-entity-recognition-with-minimal-resources/), AAAI-2020.
* **Qianhui Wu*** , Guoxin Wang*, Yuyin Zhu, Haoyan Liu, Börje Karlsson, [DeepMRT at the NTCIR-14 FinNum task: a hybrid neural model for numeral type classification in financial tweets](https://research.nii.ac.jp/ntcir/workshop/OnlineProceedings14/pdf/ntcir/07-NTCIR14-FINNUM-WuQ.pdf), NTCIR-2019.
* **Qianhui Wu**, Keqin Ding, Biqing Huang, [Approach for Fault Prognosis Using Recurrent Neural Network](https://link.springer.com/article/10.1007/s10845-018-1428-5), JIM-2018.

Honors & Awards
------
* Microsoft Machine Learning, AI & Data Science Conference (MLADS) Distinguished Contribution Award Winner (2024)
* Microsoft 2023 Global Hackathon Award Winner (2023)
* Outstanding Intern of "Stars of Tomorrow" Program, Microsoft Research Asia (2020)
* Intel Scholarship (2020)
* Second Place Winner of NTCIR-2019 FinNum Task (2019)
* Second-Class Scholarship, Tsinghua University (2018)
* Outstanding (12-9) Counselor Prize, Tsinghua University (2018)
* Outstanding Bachelor Thesis, Tsinghua University (2016)
* Second Prize of Challenge Cup, Tsinghua University (2015)
* National Encouragement Scholarship (2014)
* Scholarship of Art Excellence, Tsinghua University (2014)
* Scholarship of Academic Excellence, Tsinghua University (2013)

Other Information
------
**Academic Service**
* Conference Reviewer: ACL, EMNLP, NAACL, AAAI, NLPCC.
* Journal Reviewer: TASLP, JIM, ESIN.

**Other Activities**
* Counselor at Center for Student Learning and Development, Tsinghua University (Sep. 2016 - Aug. 2018)
* Member of Chinese National Orchestra, Tsinghua University (Aug. 2012 - Jun. 2021)

------
<div style="width: 250px; margin: auto;">
  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=sHUFovnSB1DX6vMbdeo1Jz4d6fXjO90cNXCmDhzb3e4&cl=ffffff&w=a"></script>
</div>
